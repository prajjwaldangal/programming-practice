{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from functools import reduce\n",
    "from numpy.random import default_rng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### activation function: sigmoid\n",
    "##### cost function: - correct * log (predicted)\n",
    "## for delta calculation check: https://en.wikipedia.org/wiki/Delta_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_LAYERS = 8\n",
    "def nonlin(x, deriv=False):\n",
    "    if (deriv==True):\n",
    "        return (x*(1-x))\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "with open('words.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "f.close()\n",
    "\n",
    "lines = [line[:len(line)-1] for line in lines]\n",
    "revLines = [line[::-1] for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't touch above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 45 # pneumonoultramicroscopicsilicovolcanoconiosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make x and y columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeXY():\n",
    "\n",
    "    l = len(lines)\n",
    "    X = np.empty([l, max_len])\n",
    "    Y = np.empty([l, max_len])\n",
    "    for ind, word in enumerate(lines):\n",
    "        \n",
    "        inArr = np.random.randint(1, 58, (1,max_len)) # ord('z') - 64  = 58\n",
    "        inArrRev = np.random.randint(1, 58, (1,max_len)) \n",
    "        wordLen = len(word)\n",
    "        for letIndx, let in enumerate(word):\n",
    "            inArr[0, letIndx] = ord(let) - 64\n",
    "            inArrRev[0, wordLen-1-letIndx] = ord(let) - 64\n",
    "        # inArr[letIndx+1:] = \n",
    "        X[ind] = inArr\n",
    "        Y[ind] = inArrRev\n",
    "    return X, Y\n",
    "\n",
    "X, Y = makeXY()\n",
    "X_train = X[0:20000]\n",
    "Y_train = Y[0:20000]\n",
    "X_validation = X[20001:20]\n",
    "X_test = X[20020:]\n",
    "Y_test = X[20020:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8., 33., 36., 44., 37., 57., 51., 21., 56., 12.,  6., 35., 18.,\n",
       "        21., 45., 22., 53., 51., 41., 37., 24., 55., 33., 34., 53., 22.,\n",
       "        41., 27., 16., 10., 48., 12., 33., 42., 25., 42., 40., 47., 30.,\n",
       "        55., 50., 43., 22., 52.,  6.]),\n",
       " array([57., 37., 44., 36., 33.,  8., 36., 37.,  4.,  2., 54., 50., 38.,\n",
       "        22., 38., 21., 55., 42., 18., 12., 32.,  1., 30., 45., 47., 38.,\n",
       "        30., 14., 36., 51., 57., 38., 15., 52., 11., 11., 14., 53., 57.,\n",
       "        44., 54., 53., 47.,  4., 45.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.randint(1, 20000)\n",
    "X[r], Y[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make connections between layers (synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     43,
     72
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(36)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> b 20\n",
      "Breakpoint 1 at <ipython-input-8-83d7fbd28eed>:20\n",
      "ipdb> s\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(37)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m        \u001b[0mL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> s\n",
      "--Call--\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(20)\u001b[0;36mforwardPropagation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m1\u001b[0;32m--> 20 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m    \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> s\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(22)\u001b[0;36mforwardPropagation\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;31m1\u001b[0;32m    20 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 22 \u001b[0;31m    \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x normal . normal x small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x small . small x large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> s\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(23)\u001b[0;36mforwardPropagation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     21 \u001b[0;31m    \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m    \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 23 \u001b[0;31m    \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x normal . normal x small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x small . small x large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m    \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x large . large x normal,   normal = max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p l0\n",
      "array([33.,  2., 34.,  2., 21.,  4., 32., 53., 20., 26.,  6.,  5.,  1.,\n",
      "       30., 57., 53., 27., 49., 21., 17.,  3., 44., 34., 44., 57., 25.,\n",
      "       46., 24., 39.,  1., 14.,  4., 51., 31., 43., 48., 48., 26., 23.,\n",
      "       22., 14.,  1., 24., 16.,  5.])\n",
      "ipdb> s\n",
      "--Call--\n",
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(2)\u001b[0;36mdot\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> return\n",
      "--Return--\n",
      "array([14952....221.14381898])\n",
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(6)\u001b[0;36mdot\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> return\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(24)\u001b[0;36mforwardPropagation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     22 \u001b[0;31m    \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x normal . normal x small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m    \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x small . small x large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m    \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x large . large x normal,   normal = max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0;31m# l4 = nonlin(np.dot(l3, synN))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p l1\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "ipdb> s\n",
      "--Call--\n",
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(2)\u001b[0;36mdot\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> return\n",
      "--Return--\n",
      "array([460.42...398.67514812])\n",
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(6)\u001b[0;36mdot\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> return\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(25)\u001b[0;36mforwardPropagation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x normal . normal x small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x small . small x large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x large . large x normal,   normal = max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0;31m# l4 = nonlin(np.dot(l3, synN))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p l2\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "ipdb> syn0\n",
      "array([[ 2.75996217, 21.65793225, 15.93925611, ..., 22.96646646,\n",
      "        17.92699193, 12.79535718],\n",
      "       [ 1.65991745, 25.0904328 , 21.81568736, ...,  9.77256591,\n",
      "         4.57581803, 19.84344558],\n",
      "       [ 8.24650481,  4.97056701,  1.54022522, ..., 22.9371169 ,\n",
      "        14.96001677,  7.84667831],\n",
      "       ...,\n",
      "       [18.66314544, 10.85218826, 22.51053271, ..., 20.18049259,\n",
      "        17.97274108, 16.44479988],\n",
      "       [ 6.53478516, 24.36464718, 11.75015124, ..., 17.63203935,\n",
      "        18.4624575 , 13.63532281],\n",
      "       [17.52830662, 18.74768006,  4.0257963 , ..., 14.60390584,\n",
      "        11.50587874, 13.43495235]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> np.dot(l0, syn0)\n",
      "array([14952.39071949, 16864.04585175, 17013.7703789 , 15410.9767617 ,\n",
      "       15130.95097703, 18309.32070257, 14949.63260763, 15592.73884811,\n",
      "       15338.7919841 , 15650.268388  , 15393.13198674, 14482.22446173,\n",
      "       15203.68731098, 15666.6903115 , 16873.3450366 , 16381.16215405,\n",
      "       15540.04831833, 15917.54981083, 17614.65945888, 13600.25185378,\n",
      "       16835.70089185, 17300.12048938, 18388.99454109, 16582.37693017,\n",
      "       16175.35083592, 13141.53011631, 16587.35500996, 17369.50174022,\n",
      "       19056.75297062, 16075.62045642, 15221.14381898])\n",
      "ipdb> nonlin(14952)\n",
      "1.0\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(36)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(36)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(36)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "> \u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m(36)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-83d7fbd28eed>\u001b[0m in \u001b[0;36mforwardPropagation\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x normal . normal x small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x small . small x large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x large . large x normal,   normal = max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# l4 = nonlin(np.dot(l3, synN))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c9ec7646d79a>\u001b[0m in \u001b[0;36mnonlin\u001b[0;34m(x, deriv)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l = len(lines)\n",
    "# seed is good for debugging, makes sure we start at\n",
    "# the same time\n",
    "np.random.seed(1)\n",
    "sig = 0.7 # ratio between layers\n",
    "\n",
    "# synapses (or connections)\n",
    "# np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "rng = default_rng()\n",
    "\n",
    "\n",
    "\n",
    "# the lower limit is set to 1.0 and upper is set to 26.1 because of the best and worst\n",
    "# cases. In the best case the letter in position i might be the same letter as mid+i.\n",
    "# In the worst case, the letter might an 'a' whereas it was supposed to be a 'z'\n",
    "syn0 = rng.uniform(1.0, 26.1, (max_len, int(max_len*sig)))\n",
    "syn1 = rng.uniform(1.0, 26.1, (int(max_len*sig), int(max_len/sig)))\n",
    "syn2 = rng.uniform(1.0, 26.1, (int(max_len/sig), int(max_len)))\n",
    "# synN = np.random.random((int(max_len*sig),max_len))     # this is going to be\n",
    "import pdb\n",
    "\n",
    "def forwardPropagation(x, y):\n",
    "    # forward propagation\n",
    "    l0 = x # 1 x max_len\n",
    "    l1 = nonlin(np.dot(l0, syn0)) # 1 x normal . normal x small   \n",
    "    l2 = nonlin(np.dot(l1, syn1)) # 1 x small . small x large\n",
    "    l3 = nonlin(np.dot(l2, syn2)) # 1 x large . large x normal,   normal = max_len\n",
    "    # l4 = nonlin(np.dot(l3, synN)) \n",
    "    \n",
    "    finalLayer = l3\n",
    "    return finalLayer\n",
    "\n",
    "def calculate_loss(x, y):\n",
    "    L = 0.0\n",
    "    # For each sentence...\n",
    "    N = len(y)\n",
    "    pdb.set_trace()\n",
    "    for i in np.arange(len(y)):\n",
    "        o = forwardPropagation(x[i], y[i])\n",
    "        # Add to the loss based on how off we were\n",
    "        L += y[i] * (np.log(o))\n",
    "    return -L / N\n",
    " \n",
    "def bptt(x, y):\n",
    "    T = len(x)\n",
    "    # Perform forward propagation\n",
    "    o = forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    # dLdi -> refers to delta for syni\n",
    "    dLd0 = np.zeros(syn0.shape)\n",
    "    dLd1 = np.zeros(syn1.shape)\n",
    "    dLd2 = np.zeros(syn2.shape)\n",
    "    delta_o = o\n",
    "    delta_o[y] -= 1.\n",
    "    # For each output backwards...\n",
    "    dLdV += np.outer(delta_o, s[T-1].T)\n",
    "    # Initial delta calculation\n",
    "    delta_t = self.V.T.dot(delta_o) * (1 - (s[-1] ** 2))\n",
    "    # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "    for bptt_step in np.arange(max(0, (T-1)), T)[::-1]:\n",
    "        #print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "        dLdW += np.outer(delta_t, s[bptt_step-1])\n",
    "        try:\n",
    "            X_j = model_vec[index_to_word[x[bptt_step]]]\n",
    "        except KeyError:\n",
    "            X_j = model_vec['unknown']\n",
    "        dLdU += np.outer(delta_t, X_j)\n",
    "        # Update delta for next step\n",
    "        delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    "\n",
    "# Performs one step of SGD.\n",
    "def sgd_step(x, y, learning_rate):\n",
    "    # Calculate the deltas\n",
    "    # dLdi -> refers to delta for syni\n",
    "    dLd0, dLd1, dLd2 = bptt(x, y)\n",
    "    syn0 -= learning_rate * dLd0\n",
    "    syn1 -= learning_rate * dLd1\n",
    "    syn2 -= learning_rate * dLd2\n",
    "    \n",
    "# in prediction function, we will have to take the length of a given word, round the prediction to it's \n",
    "#       closest whole number and return the result in string format\n",
    "NEPOCH = 10\n",
    "losses = []\n",
    "for _ in range(NEPOCH):\n",
    "    # calculate loss\n",
    "    loss = calculate_loss(X_train, Y_train)\n",
    "#     losses.append(loss)\n",
    "#     print(loss)\n",
    "#     if (len(losses) > 1 and losses[-1] > losses[-2]):\n",
    "#                 learning_rate = learning_rate * 0.5\n",
    "#                 print (\"Setting learning rate to %f\" % learning_rate)\n",
    "#     for i in range(len(y_train)):\n",
    "#             # One SGD step\n",
    "#             sgd_step(X_train[i], Y_train[i], learning_rate)\n",
    "#             # num_examples_seen += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function uniform:\n",
      "\n",
      "uniform(...) method of numpy.random.mtrand.RandomState instance\n",
      "    uniform(low=0.0, high=1.0, size=None)\n",
      "    \n",
      "    Draw samples from a uniform distribution.\n",
      "    \n",
      "    Samples are uniformly distributed over the half-open interval\n",
      "    ``[low, high)`` (includes low, but excludes high).  In other words,\n",
      "    any value within the given interval is equally likely to be drawn\n",
      "    by `uniform`.\n",
      "    \n",
      "    .. note::\n",
      "        New code should use the ``uniform`` method of a ``default_rng()``\n",
      "        instance instead; see `random-quick-start`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    low : float or array_like of floats, optional\n",
      "        Lower boundary of the output interval.  All values generated will be\n",
      "        greater than or equal to low.  The default value is 0.\n",
      "    high : float or array_like of floats\n",
      "        Upper boundary of the output interval.  All values generated will be\n",
      "        less than or equal to high.  The default value is 1.0.\n",
      "    size : int or tuple of ints, optional\n",
      "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "        ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "        a single value is returned if ``low`` and ``high`` are both scalars.\n",
      "        Otherwise, ``np.broadcast(low, high).size`` samples are drawn.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or scalar\n",
      "        Drawn samples from the parameterized uniform distribution.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    randint : Discrete uniform distribution, yielding integers.\n",
      "    random_integers : Discrete uniform distribution over the closed\n",
      "                      interval ``[low, high]``.\n",
      "    random_sample : Floats uniformly distributed over ``[0, 1)``.\n",
      "    random : Alias for `random_sample`.\n",
      "    rand : Convenience function that accepts dimensions as input, e.g.,\n",
      "           ``rand(2,2)`` would generate a 2-by-2 array of floats,\n",
      "           uniformly distributed over ``[0, 1)``.\n",
      "    Generator.uniform: which should be used for new code.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The probability density function of the uniform distribution is\n",
      "    \n",
      "    .. math:: p(x) = \\frac{1}{b - a}\n",
      "    \n",
      "    anywhere within the interval ``[a, b)``, and zero elsewhere.\n",
      "    \n",
      "    When ``high`` == ``low``, values of ``low`` will be returned.\n",
      "    If ``high`` < ``low``, the results are officially undefined\n",
      "    and may eventually raise an error, i.e. do not rely on this\n",
      "    function to behave when passed arguments satisfying that\n",
      "    inequality condition. The ``high`` limit may be included in the\n",
      "    returned array of floats due to floating-point rounding in the\n",
      "    equation ``low + (high-low) * random_sample()``. For example:\n",
      "    \n",
      "    >>> x = np.float32(5*0.99999999)\n",
      "    >>> x\n",
      "    5.0\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Draw samples from the distribution:\n",
      "    \n",
      "    >>> s = np.random.uniform(-1,0,1000)\n",
      "    \n",
      "    All values are within the given interval:\n",
      "    \n",
      "    >>> np.all(s >= -1)\n",
      "    True\n",
      "    >>> np.all(s < 0)\n",
      "    True\n",
      "    \n",
      "    Display the histogram of the samples, along with the\n",
      "    probability density function:\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> count, bins, ignored = plt.hist(s, 15, density=True)\n",
      "    >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25487 25487\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-04 17:22:43,302 : INFO : loading projection weights from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n",
      "2021-05-04 17:23:29,733 : INFO : loaded (3000000, 300) matrix from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the input file\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_vec = gensim.models.KeyedVectors.load_word2vec_format('/Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "_VECTOR_SIZE = int(os.environ.get('VECTOR_SIZE', '300'))\n",
    "_HIDDEN_DIM = int(os.environ.get('HIDDEN_DIM', '500'))\n",
    "_LEARNING_RATE = float(os.environ.get('LEARNING_RATE', '0.0025'))\n",
    "_NEPOCH = int(os.environ.get('NEPOCH', '10'))\n",
    "evaluate_loss_after = 2\n",
    "vocabulary_size = 25487\n",
    "\n",
    "_MODEL_FILE = os.environ.get('MODEL_FILE')\n",
    "vector_size = _VECTOR_SIZE\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "hidden_dim = _HIDDEN_DIM\n",
    "learning_rate = _LEARNING_RATE\n",
    "nepoch = _NEPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNumpy:\n",
    "     \n",
    "    def __init__(self, vector_dim , hidden_dim, label_dim = 6 , bptt_truncate = 6):\n",
    "        # Assign instance variables\n",
    "        self.label_dim = label_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        self.vector_dim = vector_dim\n",
    "        # Randomly initialize the network parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./vector_dim), np.sqrt(1./vector_dim), (hidden_dim, vector_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (label_dim, hidden_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "\n",
    "def forward_propagation(self, x):\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T+1, self.label_dim))\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        X_i = x[t]\n",
    "        s[t] = np.tanh(self.U.dot(X_i) + self.W.dot(s[t-1]))\n",
    "    o = softmax(self.V.dot(s[-2]))\n",
    "    return [o, s]\n",
    "RNNNumpy.forward_propagation = forward_propagation\n",
    "\n",
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=0)\n",
    " \n",
    "RNNNumpy.predict = predict\n",
    "\n",
    "\n",
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0.0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1.0 * (np.log(correct_word_predictions))\n",
    "    return L\n",
    " \n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    # y -> all y_train[i]\n",
    "    N = len(y)\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    " \n",
    "RNNNumpy.calculate_total_loss = calculate_total_loss\n",
    "RNNNumpy.calculate_loss = calculate_loss\n",
    "\n",
    "def bptt(self, x, y):\n",
    "    T = len(x)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[y] -= 1.\n",
    "    # For each output backwards...\n",
    "    dLdV += np.outer(delta_o, s[T-1].T)\n",
    "    # Initial delta calculation\n",
    "    delta_t = self.V.T.dot(delta_o) * (1 - (s[-1] ** 2))\n",
    "    # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "    for bptt_step in np.arange(max(0, (T-1)-self.bptt_truncate), (T-1)+1)[::-1]:\n",
    "        #print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "        dLdW += np.outer(delta_t, s[bptt_step-1])     \n",
    "        X_j = x[bptt_step]\n",
    "        dLdU += np.outer(delta_t, X_j)   \n",
    "        # Update delta for next step\n",
    "        delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    " \n",
    "RNNNumpy.bptt = bptt\n",
    "\n",
    "\n",
    "# Performs one step of SGD.\n",
    "def numpy_sgd_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    " \n",
    "RNNNumpy.sgd_step = numpy_sgd_step\n",
    "\n",
    "\n",
    "# Outer SGD Loop\n",
    "# - model: The RNN model instance\n",
    "# - X_train: The training data set\n",
    "# - y_train: The training data labels\n",
    "# - learning_rate: Initial learning rate for SGD\n",
    "# - nepoch: Number of times to iterate through the complete dataset\n",
    "# - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "def train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after):\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    print (\"There is going to be \", nepoch, \" epoches\")\n",
    "    for epoch in range(nepoch):\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "            print (\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5  \n",
    "                print (\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "        # For each training example...\n",
    "        \n",
    "        for i in range(len(y_train)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1\n",
    "    filename11 = 'numpy_model.sav'\n",
    "    pickle.dump(model, open(filename11, 'wb'))\n",
    "model = RNNNumpy(vector_size,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_course",
   "language": "python",
   "name": "linkedin_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
