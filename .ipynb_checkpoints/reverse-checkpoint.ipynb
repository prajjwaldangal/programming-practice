{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### activation function: sigmoid\n",
    "##### cost function: 1 / 2 * (correct - predicted)^2\n",
    "## for delta calculation check: https://en.wikipedia.org/wiki/Delta_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_site = \"http://svnweb.freebsd.org/csrg/share/dict/words?view=co&content-type=text/plain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_LAYERS = 8\n",
    "def nonlin(x, deriv=False):\n",
    "    if (deriv==True):\n",
    "        return (x*(1-x))\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "with open('words.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "f.close()\n",
    "\n",
    "lines = [line[:len(line)-1] for line in lines]\n",
    "revLines = [line[::-1] for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't touch above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 45 # pneumonoultramicroscopicsilicovolcanoconiosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed is good for debugging, makes sure we start at\n",
    "# the same time\n",
    "np.random.seed(1)\n",
    "sig = 0.7 # ratio between layers\n",
    "\n",
    "# synapses (or connections)\n",
    "syn0 = np.random.random((max_len, int(max_len*sig)))   # -> extends 1x3 to 1x4 as per node basis; meaning? idk\n",
    "syn1 = 2 * np.random.random((int(max_len*sig), int(max_len/sig)))\n",
    "syn2 = 2 * np.random.random((int(max_len/sig), int(max_len*sig)))\n",
    "synN = 2 * np.random.random((int(max_len*sig),max_len))     # this is going to be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make x and y columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeXY():\n",
    "\n",
    "    l = len(lines)\n",
    "    X = np.empty([l, max_len])\n",
    "    Y = np.empty([l, max_len])\n",
    "    for ind, word in enumerate(lines):\n",
    "        inArr = np.empty([1,max_len])\n",
    "        inArrRev = np.empty([1, max_len])\n",
    "        wordLen = len(word)\n",
    "        for letIndx, let in enumerate(word):\n",
    "            inArr[0, letIndx] = ord(let) - 65\n",
    "            inArrRev[0, wordLen-1-letIndx] = ord(let) - 65\n",
    "        X[ind] = inArr\n",
    "        Y[ind] = inArrRev\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = makeXY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:20000]\n",
    "Y_train = Y[0:20000]\n",
    "X_validation = X[20001:20]\n",
    "X_test = X[20020:]\n",
    "Y_test = X[20020:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(26)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> b 30\n",
      "Breakpoint 5 at <ipython-input-35-7b1eda40f6a4>:30\n",
      "ipdb> r\n",
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(30)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0mL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m5\u001b[0;32m--> 30 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;31m# in prediction function, we will have to take the length of a given word, round the prediction to it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p L\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "ipdb> r\n",
      "--Return--\n",
      "array([-0., -...0., -0., -0.])\n",
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(30)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0mL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m5\u001b[0;32m--> 30 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;31m# in prediction function, we will have to take the length of a given word, round the prediction to it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(38)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m\u001b[0mNEPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m    \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> r\n",
      "[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(26)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m    \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> b 29\n",
      "Breakpoint 6 at <ipython-input-35-7b1eda40f6a4>:29\n",
      "ipdb> r\n",
      "> \u001b[0;32m<ipython-input-35-7b1eda40f6a4>\u001b[0m(29)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m        \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Add to the loss based on how off we were\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m6\u001b[0;32m--> 29 \u001b[0;31m        \u001b[0mL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p L\n",
      "0.0\n",
      "ipdb> p y[i]\n",
      "array([3.20000000e+01, 1.55232613e-15, 1.41488764e-14, 6.91824010e-15,\n",
      "       1.19270347e-13, 1.98716361e-13, 2.98470546e-16, 2.60882109e-11,\n",
      "       2.27574491e-15, 1.67221331e-14, 6.35926431e-13, 1.64493836e-13,\n",
      "       1.93696423e-13, 9.00991124e-15, 7.91129932e-12, 5.30357203e-15,\n",
      "       5.04996345e-15, 1.52793321e-15, 6.45893802e-15, 2.79035999e-15,\n",
      "       3.03701449e-14, 8.44120068e-14, 5.06736774e-15, 6.90652593e-14,\n",
      "       3.21028236e-10, 2.69051507e-15, 8.65007076e-13, 4.95854733e-11,\n",
      "       5.35963952e-14, 3.63111189e-12, 5.86127719e-15, 5.24310642e-16,\n",
      "       2.77909750e-12, 1.60270748e-15, 3.29965475e-14, 6.23158010e-15,\n",
      "       6.67508898e-14, 3.02172032e-17, 1.58833639e-12, 1.31353743e-13,\n",
      "       3.46084484e-14, 6.42366125e-15, 7.18511549e-15, 1.14933723e-11,\n",
      "       5.45163167e-14])\n"
     ]
    }
   ],
   "source": [
    "l = len(lines)\n",
    "import pdb\n",
    "\n",
    "def forwardPropagation(x, y):\n",
    "    # forward propagation\n",
    "    l0 = x # 1 x max_len\n",
    "    l1 = nonlin(np.dot(l0, syn0)) # 1 x max_len . max_len x msm   ,  msg = max_len * sig\n",
    "    l2 = nonlin(np.dot(l1, syn1)) # 1 x msm . msm x msd   ,   msd = max_len / sig\n",
    "    l3 = nonlin(np.dot(l2, syn2)) # 1 x msd . msd x msm\n",
    "    l4 = nonlin(np.dot(l3, synN)) # 1 x msm . msm x max_len\n",
    "    \n",
    "    ls = []\n",
    "    for el in l4:\n",
    "        if el - int(el) < 0.5:\n",
    "            v = int(el)\n",
    "        else:\n",
    "            v = int(el) + 1\n",
    "        ls.append(v)\n",
    "    return ls\n",
    "\n",
    "def calculate_loss(x, y):\n",
    "    L = 0.0\n",
    "    # For each sentence...\n",
    "    N = len(y)\n",
    "    pdb.set_trace()\n",
    "    for i in np.arange(len(y)):\n",
    "        o = forwardPropagation(x[i], y[i])\n",
    "        # Add to the loss based on how off we were\n",
    "        L += y[i] * (np.log(o))\n",
    "    return -L / N\n",
    " \n",
    "# in prediction function, we will have to take the length of a given word, round the prediction to it's \n",
    "#       closest whole number and return the result in string format\n",
    "NEPOCH = 10\n",
    "for _ in range(NEPOCH):\n",
    "    # calculate loss\n",
    "    loss = calculate_loss(X_train, Y_train)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25487 25487\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-04 17:22:43,302 : INFO : loading projection weights from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n",
      "2021-05-04 17:23:29,733 : INFO : loaded (3000000, 300) matrix from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the input file\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_vec = gensim.models.KeyedVectors.load_word2vec_format('/Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "_VECTOR_SIZE = int(os.environ.get('VECTOR_SIZE', '300'))\n",
    "_HIDDEN_DIM = int(os.environ.get('HIDDEN_DIM', '500'))\n",
    "_LEARNING_RATE = float(os.environ.get('LEARNING_RATE', '0.0025'))\n",
    "_NEPOCH = int(os.environ.get('NEPOCH', '10'))\n",
    "evaluate_loss_after = 2\n",
    "vocabulary_size = 25487\n",
    "\n",
    "_MODEL_FILE = os.environ.get('MODEL_FILE')\n",
    "vector_size = _VECTOR_SIZE\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "hidden_dim = _HIDDEN_DIM\n",
    "learning_rate = _LEARNING_RATE\n",
    "nepoch = _NEPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNumpy:\n",
    "     \n",
    "    def __init__(self, vector_dim , hidden_dim, label_dim = 6 , bptt_truncate = 6):\n",
    "        # Assign instance variables\n",
    "        self.label_dim = label_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        self.vector_dim = vector_dim\n",
    "        # Randomly initialize the network parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./vector_dim), np.sqrt(1./vector_dim), (hidden_dim, vector_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (label_dim, hidden_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "\n",
    "def forward_propagation(self, x):\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T+1, self.label_dim))\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        X_i = x[t]\n",
    "        s[t] = np.tanh(self.U.dot(X_i) + self.W.dot(s[t-1]))\n",
    "    o = softmax(self.V.dot(s[-2]))\n",
    "    return [o, s]\n",
    "RNNNumpy.forward_propagation = forward_propagation\n",
    "\n",
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=0)\n",
    " \n",
    "RNNNumpy.predict = predict\n",
    "\n",
    "\n",
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0.0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1.0 * (np.log(correct_word_predictions))\n",
    "    return L\n",
    " \n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    # y -> all y_train[i]\n",
    "    N = len(y)\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    " \n",
    "RNNNumpy.calculate_total_loss = calculate_total_loss\n",
    "RNNNumpy.calculate_loss = calculate_loss\n",
    "\n",
    "def bptt(self, x, y):\n",
    "    T = len(x)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[y] -= 1.\n",
    "    # For each output backwards...\n",
    "    dLdV += np.outer(delta_o, s[T-1].T)\n",
    "    # Initial delta calculation\n",
    "    delta_t = self.V.T.dot(delta_o) * (1 - (s[-1] ** 2))\n",
    "    # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "    for bptt_step in np.arange(max(0, (T-1)-self.bptt_truncate), (T-1)+1)[::-1]:\n",
    "        #print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "        dLdW += np.outer(delta_t, s[bptt_step-1])     \n",
    "        X_j = x[bptt_step]\n",
    "        dLdU += np.outer(delta_t, X_j)   \n",
    "        # Update delta for next step\n",
    "        delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    " \n",
    "RNNNumpy.bptt = bptt\n",
    "\n",
    "\n",
    "# Performs one step of SGD.\n",
    "def numpy_sgd_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    " \n",
    "RNNNumpy.sgd_step = numpy_sgd_step\n",
    "\n",
    "\n",
    "# Outer SGD Loop\n",
    "# - model: The RNN model instance\n",
    "# - X_train: The training data set\n",
    "# - y_train: The training data labels\n",
    "# - learning_rate: Initial learning rate for SGD\n",
    "# - nepoch: Number of times to iterate through the complete dataset\n",
    "# - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "def train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after):\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    print (\"There is going to be \", nepoch, \" epoches\")\n",
    "    for epoch in range(nepoch):\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "            print (\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5  \n",
    "                print (\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "        # For each training example...\n",
    "        \n",
    "        for i in range(len(y_train)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1\n",
    "    filename11 = 'numpy_model.sav'\n",
    "    pickle.dump(model, open(filename11, 'wb'))\n",
    "model = RNNNumpy(vector_size,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_course",
   "language": "python",
   "name": "linkedin_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
