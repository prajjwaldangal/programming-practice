{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### activation function: sigmoid\n",
    "##### cost function: 1 / 2 * (correct - predicted)^2\n",
    "## for delta calculation check: https://en.wikipedia.org/wiki/Delta_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_site = \"http://svnweb.freebsd.org/csrg/share/dict/words?view=co&content-type=text/plain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_LAYERS = 8\n",
    "def nonlin(x, deriv=False):\n",
    "    if (deriv==True):\n",
    "        return (x*(1-x))\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "with open('words.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "f.close()\n",
    "\n",
    "lines = [line[:len(line)-1] for line in lines]\n",
    "revLines = [line[::-1] for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't touch above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for word in lines:\n",
    "    if len(word) > max_len:\n",
    "        max_len = len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed is good for debugging, makes sure we start at\n",
    "# the same time\n",
    "np.random.seed(1)\n",
    "sig = 0.7 # ratio between layers\n",
    "\n",
    "# synapses (or connections)\n",
    "syn0 = 2 * np.random.random((max_len, int(max_len*sig)))   # -> extends 1x3 to 1x4 as per node basis; meaning? idk\n",
    "syn1 = 2 * np.random.random((int(max_len*sig), int(max_len/sig)))\n",
    "syn2 = 2 * np.random.random((int(max_len/sig), int(max_len*sig)))\n",
    "synN = 2 * np.random.random((int(max_len*sig),max_len))     # this is going to be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.34044009e-01 1.44064899e+00 2.28749635e-04 6.04665145e-01\n",
      "  2.93511782e-01 1.84677190e-01 3.72520423e-01 6.91121454e-01\n",
      "  7.93534948e-01 1.07763347e+00 8.38389029e-01 1.37043900e+00\n",
      "  4.08904499e-01 1.75623487e+00 5.47751864e-02]\n",
      " [1.34093502e+00 8.34609605e-01 1.11737966e+00 2.80773877e-01\n",
      "  3.96202978e-01 1.60148914e+00 1.93652315e+00 6.26848356e-01\n",
      "  1.38464523e+00 1.75277830e+00 1.78921333e+00 1.70088423e-01\n",
      "  7.81095665e-02 3.39660839e-01 1.75628501e+00]\n",
      " [1.96693668e-01 8.42215250e-01 1.91577906e+00 1.06633057e+00\n",
      "  1.38375423e+00 6.31031262e-01 1.37300186e+00 1.66925134e+00\n",
      "  3.65765547e-02 1.50028863e+00 1.97772218e+00 1.49633131e+00\n",
      "  5.60887984e-01 1.57855866e+00 2.06452013e-01]\n",
      " [8.95787052e-01 1.81719101e+00 5.87228297e-01 5.75550677e-01\n",
      "  2.60057144e-01 3.87339157e-02 1.35767107e+00 4.23256232e-01\n",
      "  5.31093319e-01 9.83146319e-01 1.06725090e-01 1.14823521e+00\n",
      "  2.93457150e-01 1.17861107e+00 1.39951672e+00]\n",
      " [2.04668858e-01 8.28111976e-01 1.38880032e+00 8.28358539e-01\n",
      "  9.99069179e-02 1.07179281e+00 1.32758929e+00 1.02977822e+00\n",
      "  1.88918951e+00 1.17311008e+00 1.80680383e+00 2.74949408e-01\n",
      "  2.78552695e-01 1.61478258e+00 7.95353674e-01]\n",
      " [3.30708394e-01 1.85501716e+00 6.95531719e-01 1.50162421e+00\n",
      "  1.45199597e+00 1.76661218e+00 1.24734441e+00 1.50188487e+00\n",
      "  6.97796684e-01 5.39855784e-01 1.79177244e+00 8.56182380e-01\n",
      "  1.92968009e+00 1.32688300e+00 1.24339144e+00]\n",
      " [2.29491946e-01 1.89897852e+00 8.99824267e-01 1.15677923e+00\n",
      "  8.16273606e-01 4.74053960e-01 1.80675904e+00 1.14735897e+00\n",
      "  5.74065406e-03 1.23428983e+00 6.53289804e-01 1.05411620e+00\n",
      "  1.77188420e+00 7.14539520e-01 1.81707030e+00]\n",
      " [1.24672023e+00 3.16424857e-02 1.85887447e+00 1.38179384e+00\n",
      "  1.99464570e+00 3.44681017e-01 2.74271499e-01 1.86519093e+00\n",
      "  1.39363632e+00 1.32000345e-01 1.51092611e+00 1.50775238e+00\n",
      "  1.84604907e+00 1.42304952e+00 2.48541924e-01]\n",
      " [3.97602677e-02 5.24219738e-02 5.66129760e-02 4.92422135e-01\n",
      "  1.72005590e+00 1.07766213e+00 1.10564396e+00 1.68406178e+00\n",
      "  2.48346630e-01 5.58367358e-01 1.17151854e+00 1.93919150e+00\n",
      "  1.12206044e+00 3.72945787e-02 1.60126535e+00]\n",
      " [4.65948548e-01 1.61421039e+00 7.75721288e-01 1.72708371e+00\n",
      "  1.49424329e+00 1.11248047e+00 2.72910451e-01 1.19835379e-01\n",
      "  2.42686911e-01 8.91037571e-02 2.14988258e-01 4.51418677e-01\n",
      "  1.42597796e+00 1.11943396e+00 2.51119603e-02]\n",
      " [1.43948559e-01 1.93455266e+00 1.13620092e+00 4.06586469e-01\n",
      "  5.04651489e-01 1.48765171e+00 3.90858962e-01 1.16271785e+00\n",
      "  1.94003998e+00 1.69365760e+00 4.79695518e-01 9.87539429e-01\n",
      "  1.23991144e+00 1.65796180e+00 3.13582789e-01]\n",
      " [3.71524044e-02 1.40044287e-01 9.72690222e-01 1.21265892e+00\n",
      "  1.13770287e+00 6.34724819e-01 1.97723231e+00 1.15949044e+00\n",
      "  7.60282345e-01 1.10189644e+00 1.49066886e+00 1.33846579e+00\n",
      "  5.29839115e-01 1.32669669e-01 7.40168396e-01]\n",
      " [1.25943501e+00 4.20348020e-01 1.50551111e+00 1.33072963e-01\n",
      "  5.20630197e-01 1.60950913e+00 3.86868565e-01 1.27892176e+00\n",
      "  1.04934062e+00 1.84961594e+00 5.26593541e-01 1.31922181e-01\n",
      "  1.47013193e+00 1.54435606e+00 1.81563171e+00]\n",
      " [1.86394414e+00 2.79031460e-02 4.68724172e-01 1.23355671e+00\n",
      "  1.89803264e+00 1.90035224e+00 1.11330638e+00 1.83121270e+00\n",
      "  1.28313242e+00 7.80015428e-01 9.71981334e-01 1.20862097e+00\n",
      "  1.09909584e+00 1.85236285e+00 1.83746687e+00]\n",
      " [7.89751226e-01 1.92652506e+00 3.47911333e-01 2.52659039e-01\n",
      "  2.70158316e-01 1.01132433e+00 4.30496105e-02 1.89594042e+00\n",
      "  1.65423094e+00 3.00379615e-02 3.52392511e-01 6.64127149e-01\n",
      "  2.61993690e-01 1.61898138e+00 6.89473305e-01]\n",
      " [1.88021496e+00 1.16402836e+00 1.75766397e+00 1.68946889e+00\n",
      "  1.81078464e+00 9.19760532e-01 1.09269363e+00 1.59720718e+00\n",
      "  5.71437703e-01 9.80507045e-01 1.19822062e+00 3.10665511e-02\n",
      "  1.18696282e+00 8.67352698e-01 1.61472106e+00]\n",
      " [6.30489606e-01 1.78577742e+00 1.15571443e+00 3.68020403e-01\n",
      "  1.57585847e+00 1.22406235e+00 1.07818544e-01 8.40387360e-01\n",
      "  1.35813767e+00 1.83720356e+00 8.04049783e-04 1.95351830e+00\n",
      "  7.53160629e-01 1.94756708e+00 1.20943220e+00]\n",
      " [1.65769162e+00 1.14942301e+00 1.25615240e+00 5.71152563e-01\n",
      "  1.17366668e+00 1.50004353e+00 1.71662767e+00 1.51016438e+00\n",
      "  1.39611450e+00 1.72895886e+00 6.45361994e-01 1.34157758e+00\n",
      "  9.01747873e-01 7.64205504e-01 8.21622700e-01]\n",
      " [8.02959167e-01 6.34767892e-01 1.24383874e+00 8.60494542e-01\n",
      "  1.94760416e+00 1.35560178e+00 3.97139777e-01 8.53402019e-01\n",
      "  6.86692480e-01 1.59527761e+00 1.75999658e+00 1.80768391e+00\n",
      "  1.32543962e+00 5.40416524e-01 5.04733403e-01]\n",
      " [1.70979589e+00 1.05542929e+00 1.60432217e+00 1.14497703e+00\n",
      "  1.46628505e+00 1.03802325e+00 1.54176782e+00 1.13771598e+00\n",
      "  9.31419757e-01 6.85377816e-01 1.36418697e-01 7.55848359e-01\n",
      "  1.59252155e-01 1.96563423e+00 3.63225703e-01]\n",
      " [1.62371740e+00 1.74992329e+00 1.37682650e+00 1.13898883e+00\n",
      "  3.21942874e-01 9.33760046e-01 6.90344102e-01 4.50079916e-01\n",
      "  1.18502374e+00 6.24539675e-01 1.83261111e+00 1.81927105e+00\n",
      "  5.14236588e-01 2.21782601e-01 3.85925464e-01]\n",
      " [9.99168341e-01 1.45717134e+00 4.16388877e-01 4.96067117e-01\n",
      "  1.70334375e+00 8.31697437e-01 1.23337013e+00 4.67332278e-01\n",
      "  2.03934519e-01 1.03171403e+00 9.54281974e-01 3.05343288e-01\n",
      "  1.24361246e+00 1.08802024e+00 1.30827469e+00]] [[0.23638526 1.67399556 1.48827184 1.1810411  0.48578315 1.24649429\n",
      "  1.27671064 0.65513889 0.13497869 1.7610772  0.91991346 1.52774544\n",
      "  0.50777724 1.18277436 0.85759032 0.76420129 0.25342677 0.48853333\n",
      "  0.15868317 0.60571661 1.4834096  1.23003145]\n",
      " [1.3448222  0.01676616 1.35675394 1.00636138 0.4618169  0.34979302\n",
      "  0.36996593 1.68852001 1.96517958 1.82747925 0.69473884 1.56044916\n",
      "  1.09290918 1.6328848  0.9674539  1.1799026  1.5745269  0.20046929\n",
      "  1.07401423 0.73196669 1.20861369 1.91760503]\n",
      " [0.78564589 0.785946   1.58127399 1.2901568  0.78776802 1.3779101\n",
      "  0.80800322 0.27222631 0.90128654 0.66883879 0.43593786 1.8515496\n",
      "  1.3792788  1.19764178 1.49331494 1.08394212 1.40106615 1.86111964\n",
      "  1.72523339 0.33488372 0.52627805 0.14322056]\n",
      " [1.95734561 0.4727682  1.32119671 0.1792614  0.42154188 1.00564877\n",
      "  0.20990734 0.77774681 1.07597544 0.67840837 1.11180042 1.07353664\n",
      "  0.781221   1.39254017 1.35696491 1.3746063  1.12298252 0.71615983\n",
      "  1.22622467 1.87147253 1.19377705 1.95918035]\n",
      " [0.88201324 1.47922393 0.07520776 1.52945328 1.03656316 0.01063307\n",
      "  0.55440021 1.06966447 1.53592576 0.10618519 1.09810689 1.60198911\n",
      "  1.29916611 1.86289403 0.14946289 0.55361293 1.83847501 1.5300103\n",
      "  1.19948069 1.66593629 1.79208698 1.94544071]\n",
      " [1.99704101 0.27929867 0.14108409 0.14693331 0.02948758 1.94364015\n",
      "  0.18953383 1.68347365 1.37034599 0.97511433 0.69338976 0.70729557\n",
      "  0.50767776 1.82203595 1.45128509 0.05185159 0.92304251 0.56260255\n",
      "  0.05793237 1.76936379 1.54201072 0.65947016]\n",
      " [1.59311718 0.64927664 0.61576489 1.85621816 1.95383232 1.04711061\n",
      "  1.90387034 1.77599299 1.03606512 0.7454976  1.42070916 0.91128685\n",
      "  1.21042579 1.98081239 1.5478325  0.66855281 0.17799644 0.36981118\n",
      "  1.05370375 0.83420484 1.60131932 1.86640468]\n",
      " [0.3557295  1.72013354 1.91478985 1.91894121 0.07572518 0.11516701\n",
      "  0.01159479 0.62536231 0.11139683 0.58772497 0.71203297 1.90735404\n",
      "  0.95390184 0.55647688 1.00601039 1.28671585 0.22249135 1.51612332\n",
      "  1.70389154 1.68849972 1.78101366 0.76368479]\n",
      " [0.8876104  0.20316295 0.45161384 1.94264094 0.56924794 1.81479228\n",
      "  1.78110457 1.84500899 0.31229913 1.75944429 1.2639899  0.42125636\n",
      "  0.69023183 0.31983758 0.88869631 0.16754991 0.33063698 0.39439269\n",
      "  1.38205468 1.14760574 1.74664627 0.48926813]\n",
      " [1.25921591 0.06886253 1.03239692 1.72645296 1.96825309 0.01974595\n",
      "  0.50568296 0.44769934 0.09507519 0.02034491 0.98039062 0.09096429\n",
      "  0.55665626 1.27994914 0.58938408 0.5393094  1.18109304 0.76106815\n",
      "  1.40504607 0.9922479  1.26641853 0.70678869]\n",
      " [0.57408789 0.26641423 1.87416077 1.60967169 1.87605709 0.37076105\n",
      "  1.86631153 1.87150642 0.56708903 0.5492685  1.10286315 0.37057848\n",
      "  0.88420222 0.37063529 1.89475184 0.98764931 1.92783553 1.28988335\n",
      "  0.96863155 1.93539049 0.28637956 1.26465975]\n",
      " [1.32377674 0.86767965 0.11871445 0.9854452  0.93026789 1.61349362\n",
      "  0.51332198 0.78286073 0.48034441 1.37288683 1.97976691 0.35485907\n",
      "  1.64289348 0.46197712 0.11595163 0.27763304 1.87030623 1.77708421\n",
      "  0.57852099 1.89552813 1.69986107 0.86930959]\n",
      " [0.93609911 1.25970604 0.31606367 0.02956417 0.53102403 0.03088726\n",
      "  1.34899769 1.10293767 0.64329629 1.56040467 0.29157086 0.48976128\n",
      "  0.58462752 0.39186389 0.17587737 1.73995236 0.17637729 1.36742067\n",
      "  0.24080175 0.02139801 1.11453646 1.81421811]\n",
      " [1.72091333 0.67690277 0.05431766 1.60171871 1.61196986 1.73697623\n",
      "  1.3392932  1.61555772 1.79499656 0.9076599  1.11565061 1.01226226\n",
      "  1.38396781 1.36581374 1.04062727 1.6569363  1.01155877 1.64971712\n",
      "  0.56369018 0.35698967 1.93974114 1.48387905]\n",
      " [0.51958339 1.16247068 1.91052451 0.16150782 0.16706841 1.23826966\n",
      "  0.44898696 1.53036791 1.13630509 1.33237618 0.2156278  0.1685661\n",
      "  1.25024214 0.81946252 0.17450505 0.74212789 1.34428882 0.3791748\n",
      "  1.79145822 1.89969278 1.92314508 1.46016512]]\n"
     ]
    }
   ],
   "source": [
    "print(syn0, synN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make x and y columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeXY():\n",
    "\n",
    "    l = len(lines)\n",
    "    X = np.empty([l, max_len])\n",
    "    Y = np.empty([l, max_len])\n",
    "    for ind, word in enumerate(lines):\n",
    "        inArr = np.empty([1,max_len])\n",
    "        inArrRev = np.empty([1, max_len])\n",
    "        wordLen = len(word)\n",
    "        for letIndx, let in enumerate(word):\n",
    "            inArr[0, letIndx] = ord(let)\n",
    "            inArrRev[0, wordLen-1-letIndx] = ord(let)\n",
    "        X[ind] = inArr\n",
    "        Y[ind] = inArrRev\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = makeXY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.32192809  2.12029423  1.32192809 -3.32192809 -6.64385619 -1.\n",
      " -2.        ]\n"
     ]
    }
   ],
   "source": [
    "L = 0.0\n",
    "correct_word_predictions = np.array([0.1, 0.23, 0.4, 10, 100, 2, 4])\n",
    "L += -1.0 * (np.log2(correct_word_predictions))\n",
    "print(L)\n",
    "# help(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-101-de279adb521c>\u001b[0m(2)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0;31m# make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 1 x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> b 16\n",
      "*** Blank or comment\n",
      "ipdb> b 15\n",
      "Breakpoint 3 at <ipython-input-101-de279adb521c>:15\n",
      "ipdb> r\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "Internal StopIteration: False\n",
      "> \u001b[0;32m/opt/anaconda3/envs/linkedin_course/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m(3337)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   3335 \u001b[0;31m                        \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3336 \u001b[0;31m                        \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 3337 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3338 \u001b[0;31m                        \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3339 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> r\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-101-de279adb521c>\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m    \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x msm . msm x msd   ,   msd = max_len / sig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x msd . msd x msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m3\u001b[0;32m--> 15 \u001b[0;31m    \u001b[0ml4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x msm . msm x max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m    \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p l2\n",
      "array([[0.99999367, 0.99999967, 0.99999983, 0.99999998, 0.99999999,\n",
      "        0.99999876, 0.9999998 , 0.99999997, 0.99999938, 0.99999676,\n",
      "        0.99999956, 0.9999995 , 0.99999999, 0.99999945, 0.99999982,\n",
      "        0.99999874, 0.99999945, 0.99999954, 0.9999977 , 0.99999986,\n",
      "        0.99999999, 0.99999999, 0.99999928, 0.99999989, 0.99999916,\n",
      "        0.99999978, 0.99999963, 0.99999957, 0.99999965, 0.99999516,\n",
      "        0.99999959]])\n",
      "ipdb> p l3\n",
      "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "ipdb> p l4\n",
      "array([[0.99999992, 0.99999067, 0.99999935, 0.99999996, 0.99999752,\n",
      "        0.9999991 , 0.99999801, 0.99999998, 0.99999807, 0.99999965,\n",
      "        0.9999992 , 0.99999921, 0.9999996 , 0.99999994, 0.99999889,\n",
      "        0.9999979 , 0.99999979, 0.99999965, 0.99999973, 0.99999998,\n",
      "        1.        , 0.99999999]])\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l = len(lines)\n",
    "import pdb; pdb.set_trace()\n",
    "\n",
    "def forwardPropagation(x, y):\n",
    "    # forward propagation\n",
    "    l0 = x # 1 x max_len\n",
    "    l1 = nonlin(np.dot(l0, syn0)) # 1 x max_len . max_len x msm   ,  msg = max_len * sig\n",
    "    l2 = nonlin(np.dot(l1, syn1)) # 1 x msm . msm x msd   ,   msd = max_len / sig\n",
    "    l3 = nonlin(np.dot(l2, syn2)) # 1 x msd . msd x msm\n",
    "    l4 = nonlin(np.dot(l3, synN)) # 1 x msm . msm x max_len\n",
    "    \n",
    "    return l4\n",
    "\n",
    "def calculateLoss()\n",
    "\n",
    "for j in range(l):\n",
    "    # make a prediction\n",
    "    x = X[j] # 1 x max_len\n",
    "    x = x.reshape(1, max_len)\n",
    "    y = Y[j] #\n",
    "    y = y.reshape(1, max_len)\n",
    "    o = forwardPropagation(x, y)\n",
    "    \n",
    "    # calculate loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25487 25487\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:20000]\n",
    "y_train = Y[0:20000]\n",
    "X_validation = X[20001:20]\n",
    "X_test = X[20020:]\n",
    "Y_test = X[20020:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-04 17:22:43,302 : INFO : loading projection weights from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n",
      "2021-05-04 17:23:29,733 : INFO : loaded (3000000, 300) matrix from /Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the input file\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_vec = gensim.models.KeyedVectors.load_word2vec_format('/Users/prajjwaldangal/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "_VECTOR_SIZE = int(os.environ.get('VECTOR_SIZE', '300'))\n",
    "_HIDDEN_DIM = int(os.environ.get('HIDDEN_DIM', '500'))\n",
    "_LEARNING_RATE = float(os.environ.get('LEARNING_RATE', '0.0025'))\n",
    "_NEPOCH = int(os.environ.get('NEPOCH', '10'))\n",
    "evaluate_loss_after = 2\n",
    "vocabulary_size = 25487\n",
    "\n",
    "_MODEL_FILE = os.environ.get('MODEL_FILE')\n",
    "vector_size = _VECTOR_SIZE\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "hidden_dim = _HIDDEN_DIM\n",
    "learning_rate = _LEARNING_RATE\n",
    "nepoch = _NEPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNNumpy:\n",
    "     \n",
    "    def __init__(self, vector_dim , hidden_dim, label_dim = 6 , bptt_truncate = 6):\n",
    "        # Assign instance variables\n",
    "        self.label_dim = label_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        self.vector_dim = vector_dim\n",
    "        # Randomly initialize the network parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./vector_dim), np.sqrt(1./vector_dim), (hidden_dim, vector_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (label_dim, hidden_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "\n",
    "def forward_propagation(self, x):\n",
    "    import pdb; pdb.set_trace()\n",
    "\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros(self.label_dim)\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        X_i = x[t]\n",
    "        s[t] = np.tanh(self.U.dot(X_i) + self.W.dot(s[t-1]))\n",
    "    o = softmax(self.V.dot(s[-2]))\n",
    "    return [o, s]\n",
    "RNNNumpy.forward_propagation = forward_propagation\n",
    "\n",
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=0)\n",
    " \n",
    "RNNNumpy.predict = predict\n",
    "\n",
    "\n",
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0.0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1.0 * (np.log(correct_word_predictions))\n",
    "    return L\n",
    " \n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    # y -> all y_train[i]\n",
    "    N = len(y)\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    " \n",
    "RNNNumpy.calculate_total_loss = calculate_total_loss\n",
    "RNNNumpy.calculate_loss = calculate_loss\n",
    "\n",
    "def bptt(self, x, y):\n",
    "    T = len(x)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[y] -= 1.\n",
    "    # For each output backwards...\n",
    "    dLdV += np.outer(delta_o, s[T-1].T)\n",
    "    # Initial delta calculation\n",
    "    delta_t = self.V.T.dot(delta_o) * (1 - (s[-1] ** 2))\n",
    "    # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "    for bptt_step in np.arange(max(0, (T-1)-self.bptt_truncate), (T-1)+1)[::-1]:\n",
    "        #print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "        dLdW += np.outer(delta_t, s[bptt_step-1])     \n",
    "        X_j = x[bptt_step]\n",
    "        dLdU += np.outer(delta_t, X_j)   \n",
    "        # Update delta for next step\n",
    "        delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    " \n",
    "RNNNumpy.bptt = bptt\n",
    "\n",
    "\n",
    "# Performs one step of SGD.\n",
    "def numpy_sgd_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    " \n",
    "RNNNumpy.sgd_step = numpy_sgd_step\n",
    "\n",
    "\n",
    "\n",
    "# Outer SGD Loop\n",
    "# - model: The RNN model instance\n",
    "# - X_train: The training data set\n",
    "# - y_train: The training data labels\n",
    "# - learning_rate: Initial learning rate for SGD\n",
    "# - nepoch: Number of times to iterate through the complete dataset\n",
    "# - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "def train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after):\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    print (\"There is going to be \", nepoch, \" epoches\")\n",
    "    for epoch in range(nepoch):\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "            print (\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5  \n",
    "                print (\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "        # For each training example...\n",
    "        \n",
    "        for i in range(len(y_train)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1\n",
    "    filename11 = 'numpy_model.sav'\n",
    "    pickle.dump(model, open(filename11, 'wb'))\n",
    "model = RNNNumpy(vector_size,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is going to be  10  epoches\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (500,300) (500,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-ed16c1d00cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-946f7dfe1a1b>\u001b[0m in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d-%H-%M-%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-946f7dfe1a1b>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# y -> all y_train[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mRNNNumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_total_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-946f7dfe1a1b>\u001b[0m in \u001b[0;36mcalculate_total_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# For each sentence...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m# We only care about our prediction of the \"correct\" words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mcorrect_word_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-946f7dfe1a1b>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mX_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (500,300) (500,) "
     ]
    }
   ],
   "source": [
    "train_with_sgd(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_course",
   "language": "python",
   "name": "linkedin_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
